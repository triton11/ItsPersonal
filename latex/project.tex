%%%% ijcai19-multiauthor.tex

\typeout{IJCAI-19 Multiple authors example}

% These are the instructions for authors for IJCAI-19.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai19.sty is NOT the same than previous years'
\usepackage{ijcai19}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym} 

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.

\title{It's Personal: Using Text to Predict Myers-Briggs Personality Types}
\author{
Eric Chiu\and
Hannah Sheetz\and
Tristrum Tuttle
\affiliations
University of Pennsylvania
\emails
echiu1997@gmail, hsheetz@seas, tut@seas
}

\begin{document}
\maketitle

\begin{abstract}
Can a computer model figure out a person?s personality just based on the text of their conversations? We want to predict Myers-Briggs personality types purely based on conversational quotes. By building an effective model to categorize conversational quotes as Myers-Briggs type indicators, we will help workers understand themselves and their interactions better, improving productivity and success in the workplace. We will also build a generative model to attempt to create quotes that fall into a specified Myers-Briggs (MB) category.
\end{abstract}

\section{Problem Background}
In today?s society, more and more companies rely on personality types to help establish a company culture and even streamline recruitment. Companies like Bridgewater and Amazon use MB personality type tests to help them build effective teams and reduce friction among employees. Additionally, knowing ones own personality type is useful for figuring out career plans, building relationships, and achieving more. Because the Meyer's Briggs test is prone to bias as people are likely to answer questions with how they want to be rather than how they actually are, they can often be placed into the wrong personality type. Our project alleviates this problem of self identification by analyzing sentences said in every day social media interaction and placing them into MBTI personality types. Because the models are trained on a data set that has personality types generated by an individual and then their sentences, we know there will be some bias in this model. However, it will be more helpful in standardizing personality type identification without the interference of a person biased towards getting a certain result. 

\section{Approach}
In this project, we attempt to answer two main questions. The first question is, "can we train a model to accurately predict a person's Myers-Briggs type using just blog posts?" The second question is, "can we train a model to reproduce blog posts with a specified Myers-Briggs type?" 
\subsection{Data}
[ADD MORE] We have cleaned the text data by removing the text post break characters (three vertical lines, or $|||$). We also removed URLs from the text, because they were highly variable and did not provide useful emotional analysis in IBM Watson. We decided to leave punctuation, capitalization, and emojis in place because they imply certain types of emotion in IBM Watson. After cleaning the data, we used a Python script to add the IBM Watson emotion features to the data set. The emotional features we included were anger, joy, sadness, disgust, and fear. Each emotional feature is represented by a score from 0 to 1, corresponding to how likely the text is to convey that emotion. 

\subsection{Principle Data Analysis}

\section{Problem 1: Myers-Briggs Prediction}
To answer the question "can we train a model to predict a person's Myers-Briggs type based on their blog posts", we decided to experiment with both sentiment prediction and text prediction models. When using sentiment to predict Myers-Briggers type, we used LogReg, Random Forest, and Support Vector Machine models. When using text based prediction, we used a Naive Bayes model implemented using TF-IDF transformed documents. 
\subsection{Models}
\textbf{Naive Bayes}: The Naive Bayes model implemented using TF-IDF transformed documents. The model took the MBTI and a long post that a person with that type wrote. The vectorizer had a maximum of 2000 features, used English stop words, and had an n-gram range of $(1,3)$. Additionally, as the model was refined, more stop words were added to the NLTK stopwords. At the end of training, the top twenty words used in each MBTI type's blog posts. If a word was included in all 16 of the MBTI or in 15 of the 16 MBTI, it was added as a stop word as there was no or negligible effect on what personality types use a word more or less often.  

\subsection{Results}
\textbf{Naive Bayes}: We measured the performance of the Naive Bayes with TF-IDF by training the model on 6,999 MBTI types and their corresponding blog posts. This ensured that there were enough words to create significant features. When the training data was directly used for testing, the model returned a cross validation score of 0.5367. For five fold cross validating using the training data, the model returned cross validation scores ranging from 0.3204 to 0.3457. Finally, when the preseparated testing data was used, the model returned a cross validation score of 0.3554. The performance of all of these models increased when the additional stop words discussed above were added. Additionally, we calculated the top twenty words used by each type. Interesting, regardless of if the type was thinking or feeling, the word "feel" always scored higher than "think" or "know" within these lists. 

\section{Problem 2: Myers-Briggs Text Generation}
To answer the question "can we train a model to reproduce blog posts with a specified Myers-Briggs type?", we decided to experiment with different types of Recurrent Neural Nets (RNNs). RNNs are useful tools for text generation because they keep track of state, allowing the net to make predictions using information from previous inputs along with the current input.
\subsection{Models}
We initially built two different character-level RNNs to generate text posts. Based on our research, we reasoned that a character-level RNN would work the best for our task of text generation because they can keep track of both short term and long term memory, and the amount of training data needed is much smaller due to the number of possible characters (about 100) being much smaller than the number of possible words (about 200,000). \\ \\ 
\textbf{Linear RNN}: The first RNN had an input of a one-hot encoded character (0 or 1 for 100 features corresponding to the printable characters in python), along with 128 additional recurrent features initialized to 0. These features are fed into two linear layers simultaneously. The first linear layer has an output size of 100, and feeds into a dropout layer with dropout rate of 1\%, then the dropout layer feeds into a LogSoftmax layer with a size of 100. The second linear layer is a hidden layer, and has an output size of 128, and gets output directly alongside the LogSoftmax output. In the training loop, the LogSoftmax output is used to predict which character will follow, and the hidden layer outputs are fed into the RNN along with the actual next character as the next training instance. \\ \\
\textbf{Gated Recurrent Unit RNN}: The second RNN we built used a Gated Recurrent Unit (GRU) layer instead of a linear hidden layer. While our previous RNN is essentially only able to see one layer into the past, GRUs keep track of more previous inputs than just the most recent using a series of internal gates to decide how much an input should affect each node's output. Our GRU RNN uses an initial Embedding layer to map inputs (a number from 1 to 100, indicating the character input) to vectors of size 120, which will act as our hidden layer. Each of these vectors is then input to the GRU layer, which has an output size of 120 as well. Finally, we take the output from the GRU and feed it into a linear layer with an output size of 100, representing the character prediction.
\subsection{Results}
We measured performance of each RNN by training each RNN on 2000 blog posts randomly selected from a single category. This ensured that the RNN could receive enough information to train while not repeating a single blog post more than a handful of times. We used Cross-Entropy Loss as the criterion for back propagation, and used the Adam optimizer for forward propagation. Since training each RNN could take several hours, we decided to start by training each RNN on a single category, then choosing the best RNN to compare two different categories. We quickly discovered that the Linear RNN was not as accurate as the GRU RNN, and despite several rounds of parameter tuning, we could not reduce its Cross-Entropy Loss to below 2.50. Here is an example generated blog post from our Linear RNN, which registered a Cross-Entropy Loss of 2.5398: 
\begin{quote} 
\centering 
\textit{I, arsd, ant oha geve if te itt ou mounde te geor I pereaste ihat oEn I de mave amer an Na5x 
fer al und ond 8in t peat ounoo he link pallo tho  wast I  ouend at somessint At you,quot at oor bit ome ting than thay pe thing ab tha gconly time tore golles my /iouly acthet ing croe son tha faverinn thith bfo. } 
\end{quote}
As you can see, although some words like "thing" and "time" appear, many other words are jumbled or ill-formed. The GRU performed much better, reaching a Cross-Entropy Loss of around 1.40. Here is an example GRU generated blog post:
 \begin{quote} 
\centering 
\textit{I'm an abcd and sleep because you can think a lot of the phone (probably the word of something they say they think it such the interesting the first than the consider the nice they were all of the same than the abcds are many parted to see look and every article that so I like to it. } 
\end{quote}
The GRU RNN was able to generate posts of almost entirely correct English words and phrases, even putting together some long segments of reasonable sounding english text: "they were all of the same", "I'm an abcd", etc. We decided to use the GRU for our final text generation analysis. \\ \\

\section{Final Analysis}

\section{Conclusion}

\newpage
\section{Sources and Resources}
A pre-existing emotional analysis API \\
https://www.paralleldots.com/emotion-detection\newline
 
IBM Watson's Natural Language Understanding sentiment analysis platform\\
https://natural-language-understanding-demo.ng.bluemix.net/\newline
 
Myers-Briggs Personality Type Dataset from Kaggle\\
https://www.kaggle.com/datasnaek/mbti-type \newline

Text Generation Using Recurrent Neural Networks\\
https://towardsdatascience.com/text-generation-using-rnns-fdb03a010b9f \newline

OpenAI's GPT-2: the model, the hype, and the controversy
https://towardsdatascience.com/openais-gpt-2-the-model-the-hype-and-the-controversy-1109f4bfd5e8\\

Emotions from text: machine learning for text-based emotion prediction\\
Cecilia Ovesdotter Alm, Dan Roth, Richard Sproat\\

Image-To-Image Translation With Conditional Adversarial Networks\\
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros\\


\newpage
\section{Appendix}



\end{document}


